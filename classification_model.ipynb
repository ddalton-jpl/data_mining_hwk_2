{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GeneID</th>\n",
       "      <th>Essential</th>\n",
       "      <th>Class</th>\n",
       "      <th>Complex</th>\n",
       "      <th>Phenotype</th>\n",
       "      <th>Motif</th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Function</th>\n",
       "      <th>Localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G234064</td>\n",
       "      <td>Essential</td>\n",
       "      <td>GTP/GDP-exchange factors (GEFs)</td>\n",
       "      <td>Translation complexes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PS00824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PROTEIN SYNTHESIS</td>\n",
       "      <td>cytoplasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G234064</td>\n",
       "      <td>Essential</td>\n",
       "      <td>GTP/GDP-exchange factors (GEFs)</td>\n",
       "      <td>Translation complexes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PS00825</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CELLULAR ORGANIZATION (proteins are localized ...</td>\n",
       "      <td>cytoplasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G234064</td>\n",
       "      <td>Essential</td>\n",
       "      <td>GTP/GDP-exchange factors (GEFs)</td>\n",
       "      <td>Translation complexes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PS00825</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PROTEIN SYNTHESIS</td>\n",
       "      <td>cytoplasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G234065</td>\n",
       "      <td>Non-Essential</td>\n",
       "      <td>ATPases</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CELL RESCUE, DEFENSE, CELL DEATH AND AGEING</td>\n",
       "      <td>cytoplasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G234065</td>\n",
       "      <td>Non-Essential</td>\n",
       "      <td>ATPases</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CELLULAR ORGANIZATION (proteins are localized ...</td>\n",
       "      <td>cytoplasm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    GeneID      Essential                            Class  \\\n",
       "0  G234064      Essential  GTP/GDP-exchange factors (GEFs)   \n",
       "1  G234064      Essential  GTP/GDP-exchange factors (GEFs)   \n",
       "2  G234064      Essential  GTP/GDP-exchange factors (GEFs)   \n",
       "3  G234065  Non-Essential                          ATPases   \n",
       "4  G234065  Non-Essential                          ATPases   \n",
       "\n",
       "                 Complex Phenotype    Motif  Chromosome  \\\n",
       "0  Translation complexes       NaN  PS00824         1.0   \n",
       "1  Translation complexes       NaN  PS00825         1.0   \n",
       "2  Translation complexes       NaN  PS00825         1.0   \n",
       "3                    NaN       NaN      NaN         1.0   \n",
       "4                    NaN       NaN      NaN         1.0   \n",
       "\n",
       "                                            Function Localization  \n",
       "0                                  PROTEIN SYNTHESIS    cytoplasm  \n",
       "1  CELLULAR ORGANIZATION (proteins are localized ...    cytoplasm  \n",
       "2                                  PROTEIN SYNTHESIS    cytoplasm  \n",
       "3        CELL RESCUE, DEFENSE, CELL DEATH AND AGEING    cytoplasm  \n",
       "4  CELLULAR ORGANIZATION (proteins are localized ...    cytoplasm  "
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "file_path = 'gene_files/Genes_relation.data'\n",
    "\n",
    "# Import the data and specify the column names\n",
    "column_names = ['GeneID', 'Essential', 'Class', 'Complex', 'Phenotype', 'Motif', 'Chromosome', 'Function', 'Localization']\n",
    "df = pd.read_csv(file_path, names=column_names, header=0, na_values='?')\n",
    "\n",
    "# Print the first 5 rows of the data\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running any analysis we will run pre-processing on the data to make sure there are no duplicates and provide some normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated rows: 0.\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of duplicated rows: {}.\".format(df.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicates but there are many missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essential      133\n",
      "Class         2657\n",
      "Complex       1890\n",
      "Phenotype     1064\n",
      "Motif         2239\n",
      "Chromosome       2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Use the isna method to identify missing values\n",
    "missing = df.isna()\n",
    "\n",
    "# Count the number of missing values in each column\n",
    "missing_counts = missing.sum()\n",
    "\n",
    "# Print the number of missing values in each column\n",
    "print(missing_counts[missing_counts > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do Label encoding to allow for better normalization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset now contains 438 rows and 9 columns.\n",
      "GeneID          48\n",
      "Essential        3\n",
      "Class           15\n",
      "Complex         22\n",
      "Phenotype        9\n",
      "Motif           34\n",
      "Chromosome      15\n",
      "Function        13\n",
      "Localization     7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop the rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Print the number of rows and columns in the dataset\n",
    "print(\"The dataset now contains {} rows and {} columns.\".format(*df.shape))\n",
    "\n",
    "# Print the number of unique values for each column\n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split the dataset into a training set and a test set with a 20% hold out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 350 samples\n",
      "Test set: 88 samples\n"
     ]
    }
   ],
   "source": [
    "# Split the data into a training set and a validation set\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(df.drop('Localization', axis=1), df['Localization'], test_size=0.2)\n",
    "\n",
    "# Print the number of rows in each set\n",
    "print(\"Training set: {} samples\".format(train_data.shape[0]))\n",
    "print(\"Test set: {} samples\".format(test_data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that the data has been prepared we will implement the decision tree algorithm from scratch \n",
    "\n",
    "[Reference Algorithm](https://towardsdatascience.com/decision-tree-algorithm-in-python-from-scratch-8c43f0e40173)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create the Node class that creates nodes for the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Decision Tree class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=50, max_depth=10, n_feats=None):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_feats = n_feats\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # grow tree\n",
    "        self.n_feats = X.shape[1] if not self.n_feats else min(self.n_feats, X.shape[1])\n",
    "        self.root = self._grow_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._traverse_tree(x, self.root) for x in X]\n",
    "\n",
    "    def _gini(self, y):\n",
    "        # count number of samples at each label\n",
    "        num_samples_per_class = {label: np.sum(y == label) for label in np.unique(y)}\n",
    "        # sum weighted Gini impurity for each label\n",
    "        gini = 1.0\n",
    "        for label in num_samples_per_class:\n",
    "            prob_of_label = num_samples_per_class[label] / len(y)\n",
    "            gini -= prob_of_label ** 2\n",
    "        return gini\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        # number of samples and features\n",
    "        m, n = X.shape\n",
    "        # we cannot make a split if there are not enough samples\n",
    "        if m <= self.min_samples_split:\n",
    "            return None, None\n",
    "        # initial values\n",
    "        best_gini = 1.0\n",
    "        best_idx, best_thr = None, None\n",
    "        # grow a decision tree\n",
    "        for idx in range(n):\n",
    "            # values of feature `idx`\n",
    "            values = X[:, idx]\n",
    "            # unique values of feature `idx`\n",
    "            thresholds = np.unique(values)\n",
    "            # try all thresholds\n",
    "            for thr in thresholds:\n",
    "                # split data\n",
    "                indices_left = values <= thr\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "                # skip if the split is not valid\n",
    "                if len(y_left) == 0 or len(y_right) == 0:\n",
    "                    continue\n",
    "                # compute weighted Gini impurity\n",
    "                gini = (len(y_left) * self._gini(y_left) + len(y_right) * self._gini(y_right)) / len(y)\n",
    "                # update best\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_idx = idx\n",
    "                    best_thr = thr\n",
    "        return best_idx, best_thr\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        # number of samples at each label\n",
    "        num_samples_per_class = {label: np.sum(y == label) for label in np.unique(y)}\n",
    "        # prediction is the label that has the most samples\n",
    "        prediction = max(num_samples_per_class, key=num_samples_per_class.get)\n",
    "        # create node\n",
    "        node = Node(\n",
    "            value=prediction\n",
    "        )\n",
    "        # split data\n",
    "        idx, thr = self._best_split(X, y)\n",
    "        # grow tree\n",
    "        if idx is not None:\n",
    "            # indices of data points going left and right\n",
    "            indices_left = X[:, idx] <= thr\n",
    "            # grow left and right subtrees\n",
    "            if depth < self.max_depth:\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "                node.feature = idx\n",
    "                node.threshold = thr\n",
    "                node.left = self._grow_tree(X_left, y_left, depth + 1)\n",
    "                node.right = self._grow_tree(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        # if we have reached a leaf node, return its value\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "        # traverse left or right subtree\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a call to the Decision Tree and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTree(max_depth=5)\n",
    "tree.fit(train_data.values, train_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is 48.9%\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels for the test data\n",
    "preds = tree.predict(test_data.values)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = np.sum(preds == test_labels.values) / len(preds)\n",
    "print(\"The test accuracy is {:.1f}%\".format(accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 64-bit ('3.8.16')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "057ec9035f34ebb7d4ae5e470ecd71a5fbb474e0c09c1315adc8efda0af19b81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
